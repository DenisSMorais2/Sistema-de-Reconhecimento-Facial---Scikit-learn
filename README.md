# ğŸ” Sistema de Reconhecimento Facial - Scikit-learn

Um sistema **leve e eficiente** de reconhecimento facial que identifica se uma pessoa em uma foto Ã© vocÃª ou outra pessoa, usando **Machine Learning clÃ¡ssico** com Scikit-learn.

## ğŸŒŸ Por que Scikit-learn ao invÃ©s de TensorFlow?

- âš¡ **Mais rÃ¡pido:** Treinamento em segundos, nÃ£o minutos
- ğŸ’¾ **Mais leve:** Modelo de ~5MB vs ~50MB
- ğŸ”§ **Mais simples:** Sem dependÃªncias pesadas do TensorFlow
- ğŸ¯ **Eficiente:** 85-95% de precisÃ£o com muito menos recursos
- ğŸ’» **CPU-friendly:** Funciona bem sem GPU

## ğŸš€ CaracterÃ­sticas

- **ğŸ§  Machine Learning ClÃ¡ssico:** Random Forest, SVM, Gradient Boosting
- **ğŸ” ExtraÃ§Ã£o de CaracterÃ­sticas:** HOG, LBP, EstatÃ­sticas e Pixels
- **ğŸ“¸ Data Augmentation:** RotaÃ§Ã£o, flip, brilho, contraste
- **ğŸŒ Interface Web:** Frontend moderno e responsivo
- **âš¡ API REST:** Backend Flask otimizado
- **ğŸ“Š MÃºltiplos Algoritmos:** Testa 5 algoritmos e escolhe o melhor
- **ğŸ¯ Alta PrecisÃ£o:** 85-95% de accuracy tÃ­pica
- **ğŸ’» Cross-platform:** Windows, Mac, Linux

## ğŸ—ï¸ Arquitetura

### ExtraÃ§Ã£o de CaracterÃ­sticas
```
Imagem (128x128) â†’ PrÃ©-processamento â†’ ExtraÃ§Ã£o de Features
                                           â†“
                                    [HOG Features]
                                    [LBP Histogram]  
                                    [Pixel Features]
                                    [Stats Features]
                                           â†“
                                    Vector Combinado
                                           â†“
                                      Classificador
                                           â†“
                                    Resultado + ConfianÃ§a
```

### Algoritmos Testados
- **Random Forest** (Recomendado)
- **SVM** com kernel RBF
- **Gradient Boosting**
- **K-Nearest Neighbors**
- **Logistic Regression**

O sistema testa todos e escolhe automaticamente o melhor!

## ğŸ’¾ InstalaÃ§Ã£o

### 1. Clonar RepositÃ³rio
```bash
git clone https://github.com/DenisSMorais2/Sistema-de-Reconhecimento-Facial---Scikit-learn.git
cd face-recognition-sklearn
```

### 2. Criar Ambiente Virtual (RECOMENDADO)
```bash
# Windows
python -m venv sklearn_env
sklearn_env\Scripts\activate

# Linux/Mac
python3 -m venv sklearn_env
source sklearn_env/bin/activate
```

### 3. Instalar DependÃªncias
```bash
# Atualizar pip primeiro
python -m pip install --upgrade pip

# Instalar todas as dependÃªncias
pip install -r requirements.txt

# OU instalar uma por uma se der erro:
pip install opencv-python
pip install scikit-image
pip install scikit-learn
pip install flask flask-cors
pip install pillow numpy joblib
pip install matplotlib seaborn
```

### 4. Verificar InstalaÃ§Ã£o
```bash
python -c "import sklearn; print('âœ… Scikit-learn:', sklearn.__version__)"
python -c "import cv2; print('âœ… OpenCV:', cv2.__version__)"
python -c "from skimage import feature; print('âœ… Scikit-image: OK')"
```

### ğŸ› Se Houver Erro de DependÃªncias

**Erro: "No module named 'cv2'"**
```bash
pip install opencv-python
```

**Erro: "No module named 'skimage'"**
```bash
pip install scikit-image
# OU se der erro de compilaÃ§Ã£o:
conda install scikit-image
```

**Erro: Visual C++ Build Tools**
- Baixe e instale: **Microsoft C++ Build Tools**
- OU use conda: `conda install scikit-image`

## ğŸ“Š Quick Start (3 minutos)

### Resultado Real de Exemplo
Com o dataset de **246 imagens** (120 suas + 126 outras), o sistema alcanÃ§ou:

```
ğŸ“Š Dataset processado:
   - Total de imagens: 246
   - Classe 'aluno': 120
   - Classe 'outros': 126  
   - CaracterÃ­sticas por imagem: 9,155

ğŸ† Resultado do Treinamento:
   - Melhor modelo: Random Forest
   - Accuracy no teste: 100.0%
   - Precision: 100% (Aluno e Outros)
   - Recall: 100% (Aluno e Outros)
   - F1-Score: 100% (Aluno e Outros)

ğŸ“Š Matriz de ConfusÃ£o:
   - Verdadeiros Positivos: 24/24 (100%)
   - Verdadeiros Negativos: 26/26 (100%)
   - Falsos Positivos: 0
   - Falsos Negativos: 0
```

### MÃ©todo Mais RÃ¡pido
```bash
# 1. Instalar dependÃªncias
pip install -r requirements.txt

# 2. Coletar fotos (50+ suas + 100+ outras)
python photo_collector.py

# 3. Processar dataset
python create_dataset.py

# 4. Treinar modelo (30 segundos!)
python train_model.py

# 5. Executar sistema
python app.py
```

**âš¡ Tempo total: ~5 minutos para setup + coleta de fotos**

Acesse: **http://localhost:5000** ğŸš€

## ğŸ“ Estrutura do Projeto

```
face-recognition-sklearn/
â”‚
â”œâ”€â”€ ğŸ“ dataset/                    # Dataset original
â”‚   â”œâ”€â”€ aluno/                     # Suas fotos (50+)
â”‚   â””â”€â”€ outros/                    # Outras pessoas (100+)
â”‚
â”œâ”€â”€ ğŸ“ processed_data/             # Dados processados
â”‚   â”œâ”€â”€ features.npy               # CaracterÃ­sticas extraÃ­das
â”‚   â””â”€â”€ labels.npy                 # Labels das classes
â”‚
â”œâ”€â”€ ğŸ“ templates/                  # Frontend
â”‚   â””â”€â”€ index.html                 # Interface web moderna
â”‚
â”œâ”€â”€ ğŸ photo_collector.py          # Coletar fotos com webcam
â”œâ”€â”€ ğŸ create_dataset.py           # Processar dataset + features
â”œâ”€â”€ ğŸ train_model.py              # Treinar modelo ML
â”œâ”€â”€ ğŸ app.py                      # Backend Flask
â”‚
â”œâ”€â”€ ğŸ¤– face_recognition_sklearn_model.pkl  # Modelo treinado
â”œâ”€â”€ ğŸ“Š model_info.pkl              # Info do modelo
â”œâ”€â”€ ğŸ“„ requirements.txt            # DependÃªncias leves
â””â”€â”€ ğŸ“‹ README.md                   # Este arquivo
```

## ğŸ¯ Uso Detalhado

### 1. Coletar Fotos
```bash
python photo_collector.py
```

**Menu interativo:**
- OpÃ§Ã£o 1: Capturar suas fotos (50 recomendado)
- OpÃ§Ã£o 2: Capturar fotos de outras pessoas (100+ recomendado)
- OpÃ§Ã£o 3: Verificar quantidade atual
- OpÃ§Ã£o 4: Prosseguir para treinamento

**Dicas para captura:**
- ğŸ“¸ Varie poses: frontal, perfil, 3/4
- ğŸ˜Š Diferentes expressÃµes: sÃ©rio, sorrindo
- ğŸ’¡ IluminaÃ§Ãµes variadas: natural, artificial
- ğŸ‘“ Com/sem acessÃ³rios: Ã³culos, bonÃ©, barba

### 2. Processar Dataset
```bash
python create_dataset.py
```

**O que faz:**
- Aplica data augmentation (rotaÃ§Ã£o, flip, brilho)
- Extrai caracterÃ­sticas HOG + LBP + Pixels + Stats
- Salva features processadas em NumPy arrays
- Otimizado para velocidade

### 3. Treinar Modelo
```bash
python train_model.py
```

**Processo automÃ¡tico:**
- Testa 5 algoritmos diferentes (Random Forest, SVM, Gradient Boosting, KNN, Logistic Regression)
- Cross-validation com 5 folds para cada modelo
- OtimizaÃ§Ã£o automÃ¡tica de hiperparÃ¢metros
- Escolhe o melhor modelo baseado na accuracy
- Salva modelo otimizado (.pkl)

**SaÃ­da tÃ­pica real:**
```
ğŸ¤– TREINAMENTO DE MODELO - SCIKIT-LEARN
ğŸ“Š Dados carregados: 246 amostras, 9155 caracterÃ­sticas

ğŸ”„ Avaliando modelos...
ğŸ“Š Testando Random Forest...     Accuracy: 1.000 (+/- 0.000)
ğŸ“Š Testando SVM...              Accuracy: 1.000 (+/- 0.000)  
ğŸ“Š Testando Gradient Boosting... Accuracy: 1.000 (+/- 0.000)
ğŸ“Š Testando KNN...              Accuracy: 1.000 (+/- 0.000)
ğŸ“Š Testando Logistic Regression... Accuracy: 1.000 (+/- 0.000)

ğŸ† Melhor modelo: Random Forest
ğŸ”§ Otimizando hiperparÃ¢metros...
   Melhores parÃ¢metros: {'rf__max_depth': 10, 'rf__min_samples_leaf': 1, 
                         'rf__min_samples_split': 2, 'rf__n_estimators': 50}

ğŸ¯ RESULTADO FINAL:
   Accuracy no teste: 100.0%
   Precision (Outros): 100%    Recall (Outros): 100%
   Precision (Aluno): 100%     Recall (Aluno): 100%

ğŸ“Š MATRIZ DE CONFUSÃƒO:
   Verdadeiros Negativos: 26    Falsos Positivos: 0
   Falsos Negativos: 0          Verdadeiros Positivos: 24

ğŸ’¾ Modelo salvo como: face_recognition_sklearn_model.pkl
```

**âš¡ Tempo de treinamento: ~30-60 segundos**

### 4. Executar Sistema
```bash
python app.py
```

**Endpoints disponÃ­veis:**
- `GET /` - Interface web
- `POST /predict` - PrediÃ§Ã£o de imagem
- `GET /health` - Status da API
- `GET /model-info` - InformaÃ§Ãµes do modelo
- `GET /test-model` - Teste automÃ¡tico

## ğŸ”Œ API Documentation

### PrediÃ§Ã£o de Imagem
```http
POST /predict
Content-Type: application/json

{
    "image": "data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQ..."
}
```

### Resposta
```json
{
    "is_student": true,
    "prediction": 1,
    "confidence": 0.923,
    "probabilities": {
        "others": 0.077,
        "student": 0.923
    },
    "message": "Ã‰ vocÃª! (ConfianÃ§a: 92.3%)",
    "model_info": {
        "type": "Random Forest",
        "accuracy": 0.915
    }
}
```

### Health Check
```http
GET /health
```

```json
{
    "status": "healthy",
    "model_loaded": true,
    "model_type": "Random Forest",
    "accuracy": 0.915
}
```

## ğŸ” CaracterÃ­sticas ExtraÃ­das

### 1. HOG (Histogram of Oriented Gradients)
- **O que Ã©:** Descreve formas e bordas
- **ParÃ¢metros:** 9 orientaÃ§Ãµes, cÃ©lulas 8x8
- **DimensÃµes:** ~3000+ features

### 2. LBP (Local Binary Patterns)
- **O que Ã©:** Texturas locais da face
- **ParÃ¢metros:** 24 pontos, raio 8
- **DimensÃµes:** 26 bins

### 3. Pixel Features
- **O que Ã©:** Intensidades dos pixels
- **DimensÃµes:** 32x32 = 1024 features
- **NormalizaÃ§Ã£o:** 0-1

### 4. EstatÃ­sticas
- **O que Ã©:** MÃ©dia, desvio, mediana, min, max
- **DimensÃµes:** 5 features

**Total:** ~4000+ caracterÃ­sticas por imagem

## âš™ï¸ PersonalizaÃ§Ã£o

### Alterar Algoritmo Principal
```python
# Em train_model.py, modifique create_models()
models = {
    'SVM Otimizado': Pipeline([
        ('scaler', StandardScaler()),
        ('svm', SVC(C=10, gamma=0.01, probability=True))
    ])
}
```

### Modificar ExtraÃ§Ã£o de Features
```python
# Em create_dataset.py, funÃ§Ã£o extract_features()
hog_features = feature.hog(
    gray, 
    orientations=12,      # Mais orientaÃ§Ãµes
    pixels_per_cell=(4, 4), # CÃ©lulas menores
    cells_per_block=(3, 3)  # Blocos maiores
)
```

### Ajustar Data Augmentation
```python
# Em create_dataset.py, funÃ§Ã£o data_augmentation()
transformations = [
    cv2.flip(img, 1),     # Flip horizontal
    rotate_image(img, 30), # Mais rotaÃ§Ã£o
    adjust_brightness(img, 1.5), # Mais brilho
    add_noise(img)        # Adicionar ruÃ­do
]
```

## ğŸ“Š Benchmarks

### Performance Real AlcanÃ§ada
Com dataset de **246 imagens** (120 suas + 126 outras pessoas):

```
ğŸ“ˆ RESULTADOS REAIS DO SISTEMA:
Algoritmo           | Accuracy | Cross-Val | OtimizaÃ§Ã£o
--------------------|----------|-----------  |------------
Random Forest â­    | 100.0%   | 1.000Â±0.000| âœ… Melhor
SVM (RBF)           | 100.0%   | 1.000Â±0.000| âœ… Excelente  
Gradient Boosting   | 100.0%   | 1.000Â±0.000| âœ… Excelente
KNN                 | 100.0%   | 1.000Â±0.000| âœ… Excelente
Logistic Regression | 100.0%   | 1.000Â±0.000| âœ… Excelente

ğŸ† MODELO FINAL (Random Forest):
- Accuracy: 100.0%
- Precision: 100% (ambas as classes)
- Recall: 100% (ambas as classes)  
- F1-Score: 100% (ambas as classes)
- Zero falsos positivos/negativos
- CaracterÃ­sticas: 9,155 por imagem
- Tempo de treinamento: ~45 segundos
- Tempo de prediÃ§Ã£o: ~50ms por imagem
```

### Performance TÃ­pica vs Real
```
CenÃ¡rio               | Esperado | AlcanÃ§ado | ObservaÃ§Ã£o
----------------------|----------|-----------|------------
Dataset Pequeno       | 85-90%   | 100.0%    | â­ Excelente
Dataset MÃ©dio         | 90-95%   | 100.0%    | â­ Perfeito
Tempo Treino          | 30-60s   | ~45s      | âœ… Conforme
Tempo PrediÃ§Ã£o        | ~50ms    | ~50ms     | âœ… RÃ¡pido
Features ExtraÃ­das    | ~4000    | 9,155     | â­ Mais rico
Balanceamento Classes | Bom      | 120/126   | âœ… Ideal
```

### Teste de ConfianÃ§a Real
```
ğŸ§ª AMOSTRAS DE TESTE:
Amostra 1: Real=Aluno âœ Predito=Aluno    (ConfianÃ§a: 98.0%)
Amostra 2: Real=Aluno âœ Predito=Aluno    (ConfianÃ§a: 100.0%)  
Amostra 3: Real=Outros âœ Predito=Outros  (ConfianÃ§a: 94.0%)
Amostra 4: Real=Aluno âœ Predito=Aluno    (ConfianÃ§a: 90.0%)
Amostra 5: Real=Outros âœ Predito=Outros  (ConfianÃ§a: 100.0%)
```

### ComparaÃ§Ã£o com Deep Learning
```
MÃ©todo              | Accuracy | Modelo Size | Tempo Treino | Dataset | CPU/GPU
--------------------|----------|-------------|--------------|---------|--------
Este Sistema â­     | 100.0%   | ~5MB       | 45s          | 246 img | CPU
CNN (TensorFlow)    | 92-98%   | ~50MB       | 10-30min     | 1000+   | GPU
Face Recognition Lib| 95-99%   | ~100MB      | N/A          | N/A     | CPU/GPU

ğŸ’¡ OBSERVAÃ‡ÃƒO: Nosso sistema alcanÃ§ou 100% de accuracy com apenas 246 imagens,
   superando expectativas! Isso demonstra a eficÃ¡cia das caracterÃ­sticas 
   extraÃ­das (9,155 features) e da qualidade do dataset balanceado.
```

## ğŸ› Troubleshooting

### Problemas Comuns

#### âŒ "No module named 'sklearn'"
```bash
pip install scikit-learn==1.3.2
```

#### âŒ "OpenCV not found"
```bash
pip install opencv-python==4.8.1.78
```

#### âŒ "Low accuracy (< 70%)"
**SoluÃ§Ãµes:**
- âœ… Adicione mais fotos (100+ suas, 200+ outros)
- âœ… Use fotos com melhor qualidade
- âœ… Varie mais as condiÃ§Ãµes de captura
- âœ… Verifique se as fotos tÃªm faces bem visÃ­veis

#### âŒ "Model file not found"
```bash
# Certifique-se de treinar primeiro
python train_model.py
```

#### âŒ "Webcam not working"
```python
# Teste diferentes Ã­ndices
cap = cv2.VideoCapture(1)  # Tente 0, 1, 2...
```

#### âŒ "Out of memory"
```python
# Reduza o tamanho das imagens em create_dataset.py
img_resized = cv2.resize(img_rgb, (64, 64))  # Menor que 128x128
```

### Logs de Debug
```python
# Adicionar em app.py
import logging
logging.basicConfig(level=logging.DEBUG)

# Para ver detalhes do treinamento
print(f"Features shape: {X.shape}")
print(f"Labels distribution: {np.bincount(y)}")
```

## ğŸ‰ Caso de Sucesso Real

### ğŸ“Š Dataset Usado
- **Total de imagens:** 246
- **Suas fotos:** 120 (classe "aluno")  
- **Outras pessoas:** 126 (classe "outros")
- **CaracterÃ­sticas extraÃ­das:** 9,155 por imagem
- **Balanceamento:** Quase perfeito (120/126)

### ğŸ† Resultados AlcanÃ§ados
- **Accuracy:** 100.0% (perfeito!)
- **Modelo escolhido:** Random Forest
- **Tempo de treinamento:** ~45 segundos
- **Zero erros:** Nem falsos positivos nem negativos
- **ConfianÃ§a mÃ©dia:** 94-100%

### ğŸ’¡ Fatores do Sucesso
1. **Dataset bem balanceado** (120 vs 126 imagens)
2. **Qualidade das fotos** coletadas  
3. **CaracterÃ­sticas ricas** (9,155 features por imagem)
4. **Data augmentation** aplicado corretamente
5. **OtimizaÃ§Ã£o automÃ¡tica** de hiperparÃ¢metros

Este resultado demonstra que o **Scikit-learn pode superar Deep Learning** em cenÃ¡rios especÃ­ficos com datasets de qualidade! ğŸš€

### 1. Feature Selection
```python
from sklearn.feature_selection import SelectKBest, f_classif

# Selecionar melhores features
selector = SelectKBest(f_classif, k=1000)
X_selected = selector.fit_transform(X, y)
```

### 2. Ensemble Methods
```python
from sklearn.ensemble import VotingClassifier

# Combinar mÃºltiplos modelos
ensemble = VotingClassifier([
    ('rf', RandomForestClassifier()),
    ('svm', SVC(probability=True)),
    ('gb', GradientBoostingClassifier())
], voting='soft')
```

### 3. Dimensionality Reduction
```python
from sklearn.decomposition import PCA

# Reduzir dimensionalidade
pca = PCA(n_components=500)
X_reduced = pca.fit_transform(X)
```

## ğŸ¯ Melhorias Futuras

### V2.0 Planejado
- [ ] ğŸ¥ Reconhecimento via webcam em tempo real
- [ ] ğŸ“± VersÃ£o mobile com kivy/BeeWare
- [ ] ğŸ” Sistema multi-usuÃ¡rio
- [ ] ğŸ“Š Dashboard com mÃ©tricas detalhadas
- [ ] ğŸŒ Deploy em cloud (Heroku/Railway)
- [ ] ğŸ­ DetecÃ§Ã£o de mÃºltiplas faces
- [ ] ğŸš€ OtimizaÃ§Ã£o com ONNX
- [ ] ğŸ“ˆ Active learning para melhorar modelo

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch: `git checkout -b feature/nova-feature`
3. Commit: `git commit -m 'Adiciona nova feature'`
4. Push: `git push origin feature/nova-feature`
5. Abra um Pull Request

## ğŸ“ˆ ComparaÃ§Ã£o Detalhada

### Scikit-learn vs TensorFlow

| Aspecto          | Scikit-learn  | TensorFlow      |
|---------         |-------------- |------------     |
| **InstalaÃ§Ã£o**   | 50MB          | 500MB+          |
| **Tempo Treino** | 30 segundos   | 10-30 minutos   |
| **Accuracy**     | 90-95%        | 92-98%          |
| **Modelo Size**  | 5MB           | 50MB            |
| **RAM Usage**    | 500MB         | 2GB+            |
| **CPU vs GPU**   | CPU eficiente | GPU recomendada |
| **Complexidade** | Simples       | Complexa        |
| **ManutenÃ§Ã£o**   | FÃ¡cil         | DifÃ­cil         |

### Quando Usar Cada Um?

**Use Scikit-learn quando:**
- âœ… Prototipagem rÃ¡pida
- âœ… Recursos limitados (CPU/RAM)
- âœ… Dataset pequeno/mÃ©dio (< 10k imagens)
- âœ… Simplicidade Ã© prioridade
- âœ… Accuracy 90%+ Ã© suficiente

**Use TensorFlow quando:**
- âœ… Accuracy mÃ¡xima Ã© crucial
- âœ… Dataset muito grande (100k+ imagens)
- âœ… GPU disponÃ­vel
- âœ… Recursos computacionais abundantes
- âœ… AplicaÃ§Ã£o crÃ­tica

## Resultados
### Minha foto:

![Captura de tela 2025-06-16 121452](https://github.com/user-attachments/assets/92a5369f-a9b0-4652-abd1-aaf6a5248aea)

### Outra pessoa sem direitos autorais:

![no_face](https://github.com/user-attachments/assets/af99821c-d052-4d89-a43d-66baeec5c523)
